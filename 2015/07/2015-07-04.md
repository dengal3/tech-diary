title: "Pintos_thread"
date: 2015-07-04 10:18:11
tags:
- pintos
- thread
- os
---

在开始之前看了看[深入浅出pintos](http://wenku.baidu.com/view/3ecadb71f242336c1eb95ee1.html)，这里面有pintos用到的基本函数的说明，非常不错的。

####入门阶段
根据TA在实验中给出的第一部分提示，实现alarm-multiple
嗯，因为TA在上面写得比较详细了。我就在这里略带一下,顺便看看整个程序走下来的思路就好了。

因为pintos这里有很多样例测试，一眼看过去的话，根本不知道何从下手，其实如果想比较快地知道这个样例测试的目的的话，有个比较快的方法：那就是看那个样例测试文件的前面的注释。

举个栗子:我想知道alarm-priority这个样例想让我们实现什么。那就打开`src/test/threads/alarm-priority.c`![alarm-priority](/images/2015-07-04/alarm-priority.png)

然后综合一下样例对应的output还有result，就知道了这是希望我们当唤醒就绪列队中的线程时，我们总是让优先级高的线程先运行。

thread.c里有一个全局变量ready_list代表就绪线程，我们只要一直维持就绪线程有一个从高到低的优先级就好，在这里的话，主要就是在有ready_list的地方啦
![alarm-priority-1](/images/2015-07-04/alarm-priority-1.png)
![alarm-priority-2](/images/2015-07-04/alarm-priority-2.png)
这里主要是将list_push_back改为了list_insert_ordered，使队列成为有序的。我们要去看看list_insert_ordered的实现
```c
/* Inserts ELEM in the proper position in LIST, which must be
   sorted according to LESS given auxiliary data AUX.
   Runs in O(n) average case in the number of elements in LIST. */
void
list_insert_ordered (struct list *list, struct list_elem *elem,
                     list_less_func *less, void *aux)
{
  struct list_elem *e;

  ASSERT (list != NULL);
  ASSERT (elem != NULL);
  ASSERT (less != NULL);

  for (e = list_begin (list); e != list_end (list); e = list_next (e))
    if (less (elem, e, aux))
      break;
  return list_insert (e, elem);
}
```
这里要用到less函数作为排序的判断条件，这个是要我们自己实现的。这里要用到线程中的elem变量，还有list_entry，list_entry这个存在我觉得很有必要说清楚，因为之后在实现的过程中，这个东西就是起着很重要的作用。

一段有关list_entry的注释很好地解释了它的作用还有用法。
```c
/* Doubly linked list.

   This implementation of a doubly linked list does not require
   use of dynamically allocated memory.  Instead, each structure
   that is a potential list element must embed a struct list_elem
   member.  All of the list functions operate on these `struct
   list_elem's.  The list_entry macro allows conversion from a
   struct list_elem back to a structure object that contains it.

   For example, suppose there is a needed for a list of `struct
   foo'.  `struct foo' should contain a `struct list_elem'
   member, like so:

      struct foo
        {
          struct list_elem elem;
          int bar;
          ...other members...
        };

   Then a list of `struct foo' can be be declared and initialized
   like so:

      struct list foo_list;

      list_init (&foo_list);

   Iteration is a typical situation where it is necessary to
   convert from a struct list_elem back to its enclosing
   structure.  Here's an example using foo_list:

      struct list_elem *e;

      for (e = list_begin (&foo_list); e != list_end (&foo_list);
           e = list_next (e))
        {
          struct foo *f = list_entry (e, struct foo, elem);
          ...do something with f...
        }
*/
```
简单说来，list_entry就是一个很神奇的函数，你可以通过依次传入list_elem* elem，包含list_elem*的结构体，list_elem* 在结构体中的命名，来求出包含list_elem* elem对应的那个结构体的指针。

在less这个函数实现中elem是我们传的list
elem*,e是队列中的list_elem*,而我们想实现的是，如果elem的对应线程的优先级比e对应的线程的优先级要高时，就插到这个e的前面。具体代码实现如下
```c
/***********************************************
Function: cmp_thread_priority

Description: 比较两个线程的优先级，如果前一个线程的优先级比后面的一个优先级高，则返回true，否则返回false

Arguments: list_elem *, list_elem *, void *

Output: bool

************************************************/
bool cmp_thread_priority (struct list_elem* a, struct list_elem* b, void* aux) {
  return list_entry(a, struct thread, elem)->priority > list_entry(b, struct thread, elem)->priority; 
}
```

本来还有个地方是list_init(&ready_list),这个不影响优先级的，所以不用改也ok。

然后我们就来`make clean`&`make check`一下

![result-1](/images/2015-07-04/result-1.png)

####正式开始
借着第一个测试样例的分析，我们来简单地过一下thread的基本知识还有函数。
首先，我们去看priority-change对应的测试样例代码（thread的测试样例代码都在`src/test/threads`文件夹下）
![priority-change](/images/2015-07-04/priority-change.png)
```c
void
test_priority_change (void) 
{
  /* This test does not work with the MLFQS. */
  ASSERT (!thread_mlfqs);

  msg ("Creating a high-priority thread 2.");
  thread_create ("thread 2", PRI_DEFAULT + 1, changing_thread, NULL);
  msg ("Thread 2 should have just lowered its priority.");
  thread_set_priority (PRI_DEFAULT - 2);
  msg ("Thread 2 should have just exited.");
}

static void
changing_thread (void *aux UNUSED) 
{
  msg ("Thread 2 now lowering priority.");
  thread_set_priority (PRI_DEFAULT - 1);
  msg ("Thread 2 exiting.");
}
```
ASSERT代表断言，就是指这里的thread_mlfqs一定是false的，不然就会报错。断言有助于我们找出代码出bug 的地方。
`thread_create`函数在thread.c函数中实现,是用来创建新进程的。里面传的参数依次是线程的名字，线程的优先级，还有线程执行的函数，辅助参数。

分析之后发现，代码里面通过调用了`thread_create`函数创建了新进程，而且新进程的优先级是PRI_DEFAULT+1，比主线程的PRI_DEFAULT的还要高，所以会在主线程输出"Creating a high-priority thread 2." 之后有线程Thread 2输出的"Thread 2 now lowering priority."。所以我们在`thread_create`这个函数里面加入
``` c
    if (priority > thread_current()->priority) {
        thread_yield();
  } 
```
`thread_set_priority`将本来是优先级最高的线程的优先级降低后，该线程就要马上放弃，重新加入到就绪列表中排队，然后重新调度，来确保在运行的是所有就绪队列中优先级最高的那个。所以我们直接在`thread_set_priority`函数里面加入
``` c
    thread_yield();
```

嗯,然后我们就可以看到结果了。
![result-2](/images/2015-07-04/result-2.png)
这个一起把priority-preemt还有priority-fifo一起给过了，非常好～

然后就进入**donate**部分。
因为donate部分的实现是整个实验的重点和难点部分，所以会比较详细的解释。

首先我们要知道优先级捐赠是什么意思，这个的话TA在pdf中的解释也比较清楚了。
```
假设任务1，任务2，任务3；他们的优先级顺序分别为1 < 2 < 3。有一个稀缺资源S，S由一个锁控制为互斥访问。

任务1正在执行，并申请到了资源S；
任务3抢占了任务1的执行，任务1挂起，任务3执行；
任务3申请资源S，发现被占用，所以挂起，任务1恢复执行；
任务2抢占了任务1的执行，任务1挂起，任务2执行；
任务2执行完毕，任务1恢复；
任务1释放资源S，任务3抢占资源S，任务3执行，任务1挂起；
任务3执行完毕，任务1执行。
以上可以看出，任务2虽然比任务3优先级低，但是比任务3优先执行。也就是说任务3的优先级被降低到了任务1的级别。

     如何解决这个问题呢？最简单的思路就是一旦高优先级的任务因为低优先级任务占用资源而阻塞时，就将低优先级任务的优先级提升到等待它所占有的资源的最高优先级任务的优先级。

这样的话上述过程中的2不能抢占任务1的执行，也就不会发生优先级反转，上述过程就是我们所说的优先级捐赠。
```

首先我们来看看`priority-donate-one.c`

```c
/* The main thread acquires a lock.  Then it creates two
   higher-priority threads that block acquiring the lock, causing
   them to donate their priorities to the main thread.  When the
   main thread releases the lock, the other threads should
   acquire it in priority order.

   Based on a test originally submitted for Stanford's CS 140 in
   winter 1999 by Matt Franklin <startled@leland.stanford.edu>,
   Greg Hutchins <gmh@leland.stanford.edu>, Yu Ping Hu
   <yph@cs.stanford.edu>.  Modified by arens. */

#include <stdio.h>
#include "tests/threads/tests.h"
#include "threads/init.h"
#include "threads/synch.h"
#include "threads/thread.h"

static thread_func acquire1_thread_func;
static thread_func acquire2_thread_func;

void
test_priority_donate_one (void) 
{
  struct lock lock;

  /* This test does not work with the MLFQS. */
  ASSERT (!thread_mlfqs);

  /* Make sure our priority is the default. */
  ASSERT (thread_get_priority () == PRI_DEFAULT);

  lock_init (&lock);
  lock_acquire (&lock);
  thread_create ("acquire1", PRI_DEFAULT + 1, acquire1_thread_func, &lock);
  msg ("This thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 1, thread_get_priority ());
  thread_create ("acquire2", PRI_DEFAULT + 2, acquire2_thread_func, &lock);
  msg ("This thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 2, thread_get_priority ());
  lock_release (&lock);
  msg ("acquire2, acquire1 must already have finished, in that order.");
  msg ("This should be the last line before finishing this test.");
}

static void
acquire1_thread_func (void *lock_) 
{
  struct lock *lock = lock_;

  lock_acquire (lock);
  msg ("acquire1: got the lock");
  lock_release (lock);
  msg ("acquire1: done");
}

static void
acquire2_thread_func (void *lock_) 
{
  struct lock *lock = lock_;

  lock_acquire (lock);
  msg ("acquire2: got the lock");
  lock_release (lock);
  msg ("acquire2: done");
}
```
样例代码调用了`lock_init (&lock)`,我们去看看相关的具体实现，lock相关部分的代码都在synch.c中

我们先去看看lock的结构体，相关的代码
``` c
/* Lock. */
struct lock 
  {
    struct thread *holder;      /* Thread holding lock (for debugging). */
    struct semaphore semaphore; /* Binary semaphore controlling access. */
  };

/* A counting semaphore. */
struct semaphore 
  {
    unsigned value;             /* Current value. */
    struct list waiters;        /* List of waiting threads. */
  };
```
lock里面有个holder指针指向占有这个锁的线程，semaphore是信号量，这里也给出了它的实现，semaphore中有一个value，还有一个链表来记录在等待这个锁的线程。

lock_init(顾名思义，就是lock的初始化)
``` c
/* Initializes LOCK.  A lock can be held by at most a single
   thread at any given time.  Our locks are not "recursive", that
   is, it is an error for the thread currently holding a lock to
   try to acquire that lock.

   A lock is a specialization of a semaphore with an initial
   value of 1.  The difference between a lock and such a
   semaphore is twofold.  First, a semaphore can have a value
   greater than 1, but a lock can only be owned by a single
   thread at a time.  Second, a semaphore does not have an owner,
   meaning that one thread can "down" the semaphore and then
   another one "up" it, but with a lock the same thread must both
   acquire and release it.  When these restrictions prove
   onerous, it's a good sign that a semaphore should be used,
   instead of a lock. */
void
lock_init (struct lock *lock)
{
  ASSERT (lock != NULL);

  lock->holder = NULL;
  sema_init (&lock->semaphore, 1);
}
```
这里先将锁的占有者设为NULL，然后在调用了个sema_init函数,看看sema_init的实现

sema_init(对信号量的初始化)
``` c
/* Initializes semaphore SEMA to VALUE.  A semaphore is a
   nonnegative integer along with two atomic operators for
   manipulating it:

   - down or "P": wait for the value to become positive, then
     decrement it.

   - up or "V": increment the value (and wake up one waiting
     thread, if any). */
void
sema_init (struct semaphore *sema, unsigned value) 
{
  ASSERT (sema != NULL);

  sema->value = value;
  list_init (&sema->waiters);
}
```
根据刚刚lock传的值，就知道在lock_init中sema_init将sema的value设为了1

然后，我们看一下在synch.c中的`lock_acquire`函数具体实现
``` c
/* Acquires LOCK, sleeping until it becomes available if
   necessary.  The lock must not already be held by the current
   thread.

   This function may sleep, so it must not be called within an
   interrupt handler.  This function may be called with
   interrupts disabled, but interrupts will be turned back on if
   we need to sleep. */
void
lock_acquire (struct lock *lock)
{
  ASSERT (lock != NULL);
  ASSERT (!intr_context ());
  ASSERT (!lock_held_by_current_thread (lock));

  sema_down (&lock->semaphore);
  lock->holder = thread_current ();
}
```

这里有个sema_down函数调用了，我们继续看看sema_down函数的实现
``` c
/* Down or "P" operation on a semaphore.  Waits for SEMA's value
   to become positive and then atomically decrements it.

   This function may sleep, so it must not be called within an
   interrupt handler.  This function may be called with
   interrupts disabled, but if it sleeps then the next scheduled
   thread will probably turn interrupts back on. */
void
sema_down (struct semaphore *sema) 
{
  enum intr_level old_level;

  ASSERT (sema != NULL);
  ASSERT (!intr_context ());

  old_level = intr_disable ();
  while (sema->value == 0) 
    {
      list_push_back (&sema->waiters, &thread_current ()->elem);
      thread_block ();
    }
  sema->value--;
  intr_set_level (old_level);
}
```
如果sema->value>0，value就会递减，像lock的话value初始就是1，那么就只有一个线程可以占有lock，之后的进程调用lock_acquire的时候都会进入到循环里面，然后线程的elem就可以放到就会放到sema的等待队列中，接着调用了thread_block就会将进程变成等待的状态。

直到占有lock的线程调用了`lock_release`
lock_release:
```c
/* Releases LOCK, which must be owned by the current thread.

   An interrupt handler cannot acquire a lock, so it does not
   make sense to try to release a lock within an interrupt
   handler. */
void
lock_release (struct lock *lock) 
{
  ASSERT (lock != NULL);
  ASSERT (lock_held_by_current_thread (lock));

  lock->holder = NULL;
  sema_up (&lock->semaphore);
}
```
这里其实很明显就是和lock_acquire还有sema_down是相对应的，我们继续来去看看sema_up
sema_up:
```c
/* Up or "V" operation on a semaphore.  Increments SEMA's value
   and wakes up one thread of those waiting for SEMA, if any.

   This function may be called from an interrupt handler. */
void
sema_up (struct semaphore *sema) 
{
  enum intr_level old_level;

  ASSERT (sema != NULL);

  old_level = intr_disable ();
  if (!list_empty (&sema->waiters)) 
    thread_unblock (list_entry (list_pop_front (&sema->waiters),
                                struct thread, elem));
  sema->value++;
  intr_set_level (old_level);
}
```
当释放锁时，如果锁中等待的队列不为空，那么就将队列中的第一个list_elem弹出，这里又见到了上面提到的list_entry了，所以我们知道得到的是弹出的list_elem对应的线程，然后这个进程unblock，就是将这个线程重新放到就绪队列中，接着value变回了1。

很好，然后我们就知道类似前面的使ready_list保持有序状态一样，我们让lock的wait_list也成为有序状态就好了。
具体实现就也是将list_push_back改为list_insert_ordered，然后函数也是用上面那个比较线程优先级就好了～
在sema_down中修改list_push_back函数，改为
```c
list_insert_ordered (&sema->waiters, &thread_current ()->elem, &cmp_thread_priority, NULL);
```

这个时候的样例输出就可以保证在main释放锁之后，acquire2在acquire1前面得到lock了。

然后我们来看看测试这个样例的输出，可以直接在终端下`$ pintos run priority-donate-one`看到
![priority-donate-one-1](/images/2015-07-04/priority-donate-one-1.png)

很奇怪，为什么"acquire2: got the lock"会出现在"end"的后面？

首先我们来分析一下,"acquire2"出现了，而"acquire1"还没出现，说明我们这里处理的优先级是对的。我一开始以为一个线程给的tick运行的时间是很短的，线程马上就会切换，所以觉得很奇怪：acquire2的优先级比main高，所以这时候不是应该会抢夺过来了吗。。后来我上网查了一下才发现，这里的一个tick差不多可以跑10000次循环，所以要等到线程的正常切换是不可能的。而出现输出这样现象，我猜测是因为main运行的tick还没够，所以它会继续运行下面的代码，然后结束了主线程，而这时候的acquire2才从就绪队列中唤醒。

做了个小实验来验证一下，一次tick大概能做10000次循环，假设我们的优先级都是对的，那么我在实验样例测试源码中加入循环
![priority-donate-one-testing](/images/2015-07-04/priority-donate-one-2.png)
然后我们单独地再测试一次priority-donate-one，就发现
![priority-donate-one-testing1](/images/2015-07-04/priority-donate-one-3.png)
测试就pass了。这就说明我们的猜想是正确的。所以我们就在sema_up那里加一个`thread_yield`函数，有锁释放时，我们就要马上重新调度。

这个样例其实还不需要用到优先级捐赠，可以用来检测自己的lock_waiters优先级排序呀，锁释放后的进程切换呀相关这个基础代码没有问题了，再继续开始后面的。

接下来的才是donate最核心要关注的问题。

我们可以去看看donate测试系列的测试代码的注释
priority-donate-lower:
```c
/* The main thread acquires a lock.  Then it creates a
   higher-priority thread that blocks acquiring the lock, causing
   it to donate their priorities to the main thread.  The main
   thread attempts to lower its priority, which should not take
   effect until the donation is released. */
```
priority-donate-multiple:
```c
/* The main thread acquires locks A and B, then it creates two
   higher-priority threads.  Each of these threads blocks
   acquiring one of the locks and thus donate their priority to
   the main thread.  The main thread releases the locks in turn
   and relinquishes its donated priorities.
*/
```
priority-donate-nest:
```c
/* Low-priority main thread L acquires lock A.  Medium-priority
thread M then acquires lock B then blocks on acquiring lock A.
High-priority thread H then blocks on acquiring lock B.  Thus,
thread H donates its priority to M, which in turn donates it
to thread L.
*/
```
这里有提到几点：

1. 当释放锁时线程要放弃之前捐献的优先级，回到它自己的本身优先级上
2. 如果线程在占有着锁时降低线程的优先级，这个降低的优先级不会影响到线程直到线程释放锁
3. 捐献是具有可传递性的，当发生嵌套时，假设L线程占有A锁，M线程占有B锁在请求A锁，H线程在请求B锁，H线程的优先级就会先捐献给M线程，然后M线程就又捐献给L线程。
4. 一个进程有多个锁的话将会以所有锁中的所有等待队列的线程中的最高优先级作为外显优先级

第一，二点就要求我们的thread结构要有base_priority还有priority两个记录不同优先级的变量，一个是记录线程本身应有的优先级，一个是记录线程表现出来的优先级。

第三点要实现的话，我们就还要给每个thread加一个记录thread等待的lock的变量，虽然在第一层的时候可以通过lock的holder知道，但是往上的线程在等待的lock就不知道了。

第四点就要求thread结构体内还要有lock_list来记录这个线程所拥有的锁，这样才可以不断地挑出最高的优先级。

其实整个donate就一个比较大的部分要实现，那就是更新相关线程的优先级。要用到更新的地方有：有线程要加入waiter队列时，set_thread_priority中线程的优先级发生变化时，lock_release释放锁的时候

当然每个情况下都有细节要考虑的。

1. 加入waiter队列时：

在lock_acquire中加入waiting_lock的设定
```c
void
lock_acquire (struct lock *lock)
{
  ASSERT (lock != NULL);
  ASSERT (!intr_context ());
  ASSERT (!lock_held_by_current_thread (lock));

  struct thread* holder_thread = lock->holder;
  if (holder_thread != NULL) {  /* 这个锁已被占有 */
    thread_current()->waiting_lock = lock;
  }
  sema_down (&lock->semaphore);
  lock->holder = thread_current ();
  list_push_back(&lock->holder->lock_list, &lock->elem); /*  将这个锁的elem放到线程的lock_list中 */
}
```
在sema_down中调用更新优先级的函数
```c
void
sema_down (struct semaphore *sema) 
{
  enum intr_level old_level;

  ASSERT (sema != NULL);
  ASSERT (!intr_context ());

  old_level = intr_disable ();
  while (sema->value == 0) 
    {
      list_insert_ordered (&sema->waiters, &thread_current ()->elem, &cmp_thread_priority, NULL);
      if (thread_current()->waiting_lock != NULL)  //加入更新优先级函数
        update_relative_threads_priority(thread_current()->waiting_lock->holder);
      thread_block ();
    }
  thread_current()->waiting_lock = NULL;
  sema->value--;
  intr_set_level (old_level);
}
```
更新优先级的函数实现先放一放，先把其他两个情况给考虑了。

2. set_thread_priority那里直接加就好了
3. 在释放锁时

我们首先在lock_release中加入了remove_lock_from_holer_thread函数
就代表从current_thread中释放掉锁了。

remove_lock_from_holder_thread:
```c
void remove_lock_from_holder_thread(struct lock* l) {
  struct thread* holder_thread = l->holder;
  list_remove(&l->elem);
  update_relative_threads_priority(holder_thread);
  return;
}
```
就是从线程的lock_list中移除要释放的lock，然后再更新相关线程的优先级。

然后现在我们来讲一下更新相关线程优先级的函数`update_relative_threads_priority`的实现
```c
/**************************************
name: update_relative_threads_priority

Description: 根据现有线程的优先级，不断迭代更新在等待的资源的holder的优先级

arguments: thread *

output: void
***************************************/
void update_relative_threads_priority(struct thread* a) {
  ASSERT(a != NULL);
  while (a != NULL) {
    if (!list_empty(&a->lock_list)) {
        list_sort(&a->lock_list, &cmp_lock_list_priority, NULL); //将lock_list中的对象按他们的优先级排序
        struct list *waiters = &((list_entry(list_front(&a->lock_list), struct lock, elem))->semaphore.waiters);
        int newest_highest_priority = 0;
        if (!list_empty(waiters)) {
           newest_highest_priority = list_entry(list_front(waiters), struct thread, elem)->priority;  //mark
         }
        a->priority = newest_highest_priority > a->base_priority?newest_highest_priority:a->base_priority;
    } else {
      a->priority = a->base_priority;
    }
    if (a->waiting_lock != NULL)
      a = a->waiting_lock->holder;
    else break;
  }
  return;
}
```
当输入的线程的lock_list不为空时，即a占有锁，这是为了保护list_sort里面的断言，然后就用list_sort排序，具体排序的判断函数是比较lock_list里面的elem所对应的lock的waiters队列中第一个线程的优先级，具体实现等下再讲。排好序后我们就可以从lock_list队列中弹出一个elem对应的lock的waiters队列，这个队列中含有最高的优先级的线程，然后就继续弹出等待队列的elem所对应的线程，然后这个线程的优先级就是我们想要的，和线程本身的优先级比较一下即可。在这个过程通过waiting_lock->holder进行下去，这个就保证了优先级的可传递性。

cmp_lock_list_priority的实现：
```c
/**************************************************

name: cmp_lock_list_priority

Description: 比较lock_list里面的所有锁的最高优先级

arguments: list_elem *a, list_elem *b, void *

output: bool

****************************************************/
bool cmp_lock_list_priority(struct list_elem *a, struct list_elem *b, void *aux) {
  ASSERT(a != NULL)
  int a_thread_priority, b_thread_priority;

  if (a != NULL && b != NULL) {
    struct list *a_lock_list = &(list_entry(a, struct lock, elem)->semaphore.waiters);
    struct list *b_lock_list = &(list_entry(b, struct lock, elem)->semaphore.waiters);

      a_thread_priority = !list_empty(a_lock_list)? list_entry(list_front(a_lock_list), struct thread, elem)->priority:0;
      b_thread_priority = !list_empty(b_lock_list)? list_entry(list_front(b_lock_list), struct thread, elem)->priority:0;
    return a_thread_priority > b_thread_priority;
  }
  return 0;
}
```
完成后测试一下
![priority-donate-result-1](/images/2015-07-04/priority-donate-result-1.png)
还有一些细节要改进的

比如设置优先级还有sema_up

![priority-donate-improved-1](/images/2015-07-04/priority-donate-improved-1.png)

再去跑一次

![priority-donate-result-2](/images/2015-07-04/priority-donate-result-2.png)

还差一个！这个是有关condition的，和之前的sema类似，也是排一下序

![priority-donate-condvar](/images/2015-07-04/priority-donate-condvar.png)

终于QAQ！！donate的做完了。

然后我们进入mlfqs部分的。这个部分的话，就是涉及多级反馈队列调度。

简单来说就是维持了64个队列，每个队列对应一个优先级，从PRI_MIN到PRI_MAX。然后通过一些公式计算来计算出线程当前的优先级，系统调度的时候会从高优先级队列开始选择线程执行，如果最高非空的优先级队列存在多个线程则使用轮转的方式在这多个线程中进行调度。值得注意的是，这里线程的优先级随着操作系统的运转数据而动态改变。

这个部分的文档比较详细。主要的部分在timer_interrupt里面根据tick的情况不一样，调用不同的更新函数。
在timer_interrupt中加入
```c
if (thread_mlfqs) {
    update_recent_cpu_every_tick();

    if (ticks%TIMER_FREQ == 0) {
      renew_load_avg();
      renew_all_thread_recent_cpu();
      renew_all_thread_priority();
    } else if (ticks%4 == 0) {
      renew_all_thread_priority();
    }
}
```
然后每个函数的具体实现在这里
```c
/***************************************
name: renew_all_thread_recent_cpu

Description: 将所有线程的recent_cpu都重新计算一次

arguments: none

output: void
****************************************/
void renew_all_thread_recent_cpu() {
  struct list_elem *e;

  for (e = list_begin (&all_list); e != list_end (&all_list);
       e = list_next (e))
    {
      struct thread *t = list_entry (e, struct thread, allelem);
      if (t != idle_thread)
        renew_recent_cpu(t);
    }
}

/***************************************
name: renew_all_thread_priority

Description: 将所有线程的recent_cpu都重新计算一次

arguments: none

output: void
****************************************/
void renew_all_thread_priority() {
  struct list_elem *e;

  for (e = list_begin (&all_list); e != list_end (&all_list);
       e = list_next (e))
    {
      struct thread *t = list_entry (e, struct thread, allelem);
      if (t != idle_thread)
        renew_thread_priority(t);
    }
}

/***************************************
name: renew_recent_cpu

Description: 将线程的recent_cpu
重新计算一次

argement: struct thread *t

output: void
****************************************/
void renew_recent_cpu(struct thread *t) {
  t->recent_cpu = FP_ADD_MIX (FP_MULT (FP_DIV (FP_MULT_MIX (load_avg, 2), FP_ADD_MIX (FP_MULT_MIX (load_avg, 2), 1)), t->recent_cpu), t->nice);
}

/***************************************
name: renew_thread_priority

Description: 将线程的priority
重新计算一次

argement: struct thread *t

output: void
****************************************/
void renew_thread_priority(struct thread *t) {
  if (t == idle_thread)
    return;
  t->priority = FP_INT_PART (FP_SUB_MIX (FP_SUB (FP_CONST (PRI_MAX), FP_DIV_MIX (t->recent_cpu, 4)), 2 * t->nice));
  t->priority = t->priority < PRI_MIN ? PRI_MIN : t->priority;
  t->priority = t->priority > PRI_MAX ? PRI_MAX : t->priority;
}

/***************************************
name: renew_load_avg

Description: 更新load_avg

argement: none

output: void
****************************************/
void renew_load_avg() {
  load_avg = FP_ADD (FP_DIV_MIX (FP_MULT_MIX (load_avg, 59), 60), FP_DIV_MIX (FP_CONST (get_all_ready_list_amount()), 60));;
}

```
然后，浮点计算的实现油鱼时间的关系，也是借鉴了一下网上的代码了QAQ
```c
#ifndef __THREAD_FIXED_POINT_H
#define __THREAD_FIXED_POINT_H

/* Basic definitions of fixed point. */
typedef int fixed_t;
/* 16 LSB used for fractional part. */
#define FP_SHIFT_AMOUNT 16
/* Convert a value to fixed-point value. */
#define FP_CONST(A) ((fixed_t)(A << FP_SHIFT_AMOUNT))
/* Add two fixed-point value. */
#define FP_ADD(A,B) (A + B)
/* Add a fixed-point value A and an int value B. */
#define FP_ADD_MIX(A,B) (A + (B << FP_SHIFT_AMOUNT))
/* Substract two fixed-point value. */
#define FP_SUB(A,B) (A - B)
/* Substract an int value B from a fixed-point value A */
#define FP_SUB_MIX(A,B) (A - (B << FP_SHIFT_AMOUNT))
/* Multiply a fixed-point value A by an int value B. */
#define FP_MULT_MIX(A,B) (A * B)
/* Divide a fixed-point value A by an int value B. */
#define FP_DIV_MIX(A,B) (A / B)
/* Multiply two fixed-point value. */
#define FP_MULT(A,B) ((fixed_t)(((int64_t) A) * B >> FP_SHIFT_AMOUNT))
/* Divide two fixed-point value. */
#define FP_DIV(A,B) ((fixed_t)((((int64_t) A) << FP_SHIFT_AMOUNT) / B))
/* Get integer part of a fixed-point value. */
#define FP_INT_PART(A) (A >> FP_SHIFT_AMOUNT)
/* Get rounded integer of a fixed-point value. */
#define FP_ROUND(A) (A >= 0 ? ((A + (1 << (FP_SHIFT_AMOUNT - 1))) >> FP_SHIFT_AMOUNT) \
        : ((A - (1 << (FP_SHIFT_AMOUNT - 1))) >> FP_SHIFT_AMOUNT))

#endif /* thread/fixed_point.h */
```
但是跑出来的结果是mlqs部分全fail

其中，mlfqs-fair-2出来的结果是这样的
![mlfqs-problem](/images/2015-07-04/mlfqs-problem.png)

里面跑出来的tick太少了，有可能是在timer_sleep中检测一个tick的时间是用忙等待的方法实现的，这样其实会使线程应得的tick数减低，我们要改进timer_sleep的等待方法,这里也是借鉴了一下网上的代码完成的

```c
/* Sleeps for approximately TICKS timer ticks.  Interrupts must
   be turned on. */
void
timer_sleep (int64_t ticks)
{
  if (ticks <= 0)
  {
    return;
  }
  ASSERT (intr_get_level () == INTR_ON);
  enum intr_level old_level = intr_disable ();
  struct thread *current_thread = thread_current ();
  current_thread->blocked_ticks = ticks;
  thread_block ();
  intr_set_level (old_level);
}

/* Timer interrupt handler. */
static void
timer_interrupt (struct intr_frame *args UNUSED)
{
  ticks++;
  enum intr_level old_level = intr_disable ();

  if (thread_mlfqs) {
    update_recent_cpu_every_tick();

    if (ticks%TIMER_FREQ == 0) {
      renew_load_avg();
      renew_all_thread_recent_cpu();
      renew_all_thread_priority();
    } else if (ticks%4 == 0) {
      renew_all_thread_priority();
    }
  }
  thread_foreach (blocked_thread_check, NULL);
  intr_set_level (old_level);
  thread_tick ();
}

/* Check the blocked thread */
void
blocked_thread_check (struct thread *t, void *aux UNUSED)
{
  if (t->status == THREAD_BLOCKED && t->blocked_ticks > 0)
  {
      t->blocked_ticks--;
      if (t->blocked_ticks == 0)
      {
          thread_unblock(t);
      }
  }
}

```

再去跑一次
![mlfqs-result](/images/2015-07-04/mlfqs-result.png)

还有两个。其中一个mlfqs-load-avg.c中是这么说的
```c
/*
If your implementation fails this test but passes most other
   tests, then consider whether you are doing too much work in
   the timer interrupt.  If the timer interrupt handler takes too
   long, then the test's main thread will not have enough time to
   do its own work (printing a message) and go back to sleep
   before the next tick arrives.  Then the main thread will be
   ready, instead of sleeping, when the tick arrives,
   artificially driving up the load average.
   */
```
目测是我的timer interrupt里面做的东西太多了，可能是priority-donate那部分里面写的代码要改进一下，因为我之前在debug的时候发现在程序进行的时候会多次用到lock的，而我的donate部分实现的代码有点累赘，所以应该还是可以改进一下的。

但是因为要期末考复习了，所以就只能先到这里了QAQ。

####感想：
因为这个project是在边复习边打的代码，所以完成得有点仓促，不过真的也在里面投入了很多的时间还有心血，起码有关线程部分里面的东西，我期末考不怎么担心了QAQ。我觉得其实这个实验还是挺有趣的，但是下次布置的时间可以再推前一点就更好了～毕竟，一边复习一边搞这个也是有点呛。嗯，本来想放到github上面的，中间做的过程可以看得清楚点，但是中间才想起来，前面的commit也补不上了，所以就不给地址了。而且因为报告是用的md写的，所以转成pdf的时候代码块有些地方可能就看不到了，这个就不好意思了QAQ。















